{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAdOy-N89Q4n"
      },
      "source": [
        "# Technical Test PT Allure - CV Matcher - Muhammad Luthfi Juliandri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "svKWn2Vs9Q4o",
        "outputId": "c22cc616-34ed-45b4-f7fe-7d1f60753a68"
      },
      "source": [
        "!pip install pdfplumber gradio sentence-transformers pandas scikit-learn"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG7tTWf9Q4p"
      },
      "source": [
        "import gradio as gr\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from datetime import datetime\n",
        "\n",
        "model_embed = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "clf = None"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZEQLomz9Q4p"
      },
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        return \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE6dA52h9Q4p"
      },
      "source": [
        "def estimate_experience_years(text):\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "\n",
        "    now = datetime.now()\n",
        "    lines = text.lower().splitlines()\n",
        "\n",
        "    experience_headings = [\n",
        "        'work experience', 'work experiences', 'professional experience',\n",
        "        'experiences', 'pengalaman kerja', 'riwayat karier', 'riwayat pekerjaan'\n",
        "    ]\n",
        "    stop_headings = ['education', 'pendidikan', 'academic background', 'school', 'university']\n",
        "\n",
        "\n",
        "    def normalize(line):\n",
        "        return line.replace(' ', '').strip()\n",
        "\n",
        "    start_idx = None\n",
        "    stop_idx = None\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        norm_line = normalize(line)\n",
        "        if start_idx is None and any(normalize(k) in norm_line for k in experience_headings):\n",
        "            start_idx = i\n",
        "        elif start_idx is not None and any(normalize(k) in norm_line for k in stop_headings):\n",
        "            stop_idx = i\n",
        "            break\n",
        "\n",
        "    if start_idx is None:\n",
        "        return 0.0\n",
        "\n",
        "    section = lines[start_idx : stop_idx or start_idx + 40]\n",
        "\n",
        "    pattern = re.compile(r'(20\\d{2})\\s*[-–]\\s*(20\\d{2}|present|sekarang|saat ini)', flags=re.IGNORECASE)\n",
        "\n",
        "    years = []\n",
        "    for line in section:\n",
        "        for sy, ey in pattern.findall(line):\n",
        "            try:\n",
        "                start_year = int(sy)\n",
        "                end_year = int(ey) if ey.isdigit() else now.year\n",
        "                years.append((start_year, end_year))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if not years:\n",
        "        return 0.0\n",
        "\n",
        "    min_start = min(y[0] for y in years)\n",
        "    max_end = max(y[1] for y in years)\n",
        "\n",
        "    return round (max_end - min_start, 1)\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14fchWjj9Q4p"
      },
      "source": [
        "def count_skill_matches(text, skills):\n",
        "    return sum(1 for s in skills if s.lower() in text.lower())"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsonYXRT9Q4p"
      },
      "source": [
        "def train_realistic_model():\n",
        "    global clf\n",
        "    data = [\n",
        "        [3, 5, 70, 1200, 1],\n",
        "        [2, 4, 60, 1000, 1],\n",
        "        [1, 10, 30, 1500, 0],\n",
        "        [0, 0, 20, 900, 0],\n",
        "        [3, 2, 65, 1100, 1],\n",
        "        [0, 7, 25, 800, 0],\n",
        "        [2, 1, 55, 950, 1],\n",
        "        [1, 0, 40, 700, 0]\n",
        "    ]\n",
        "    df = pd.DataFrame(data, columns=[\"skill\", \"exp\", \"sim\", \"length\", \"label\"])\n",
        "    X = df[[\"skill\", \"exp\", \"sim\", \"length\"]]\n",
        "    y = df[\"label\"]\n",
        "    clf = RandomForestClassifier()\n",
        "    clf.fit(X, y)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAt_inUe9Q4p"
      },
      "source": [
        "def match_cv_realistic(job_title, skills_csv, min_exp, cvs):\n",
        "    skills = [s.strip().lower() for s in skills_csv.split(',') if s.strip()]\n",
        "    job_text = f\"Kami mencari {job_title} yang menguasai {', '.join(skills)}\"\n",
        "    results = []\n",
        "    for cv in cvs:\n",
        "        try:\n",
        "            text = extract_text_from_pdf(cv.name)\n",
        "            skill_score = count_skill_matches(text, skills)\n",
        "            exp_years = estimate_experience_years(text)\n",
        "            emb_cv = model_embed.encode(text, convert_to_tensor=True)\n",
        "            emb_job = model_embed.encode(job_text, convert_to_tensor=True)\n",
        "            sim_score = util.cos_sim(emb_cv, emb_job).item() * 100\n",
        "            length = len(text.split())\n",
        "            features = np.array([[skill_score, exp_years, sim_score * 2, length]])\n",
        "            pred = clf.predict_proba(features)[0][1]\n",
        "            alasan = []\n",
        "            if exp_years < min_exp:\n",
        "                pred *= 0.5\n",
        "                alasan.append(f'Pengalaman kurang dari {min_exp} tahun')\n",
        "            if skill_score == 0:\n",
        "                alasan.append('Tidak ada skill yang cocok')\n",
        "            if sim_score < 40:\n",
        "                alasan.append('Similarity rendah')\n",
        "            if not alasan:\n",
        "                alasan.append('Cocok dengan deskripsi pekerjaan')\n",
        "            results.append({\n",
        "                'Filename': cv.name.split('/')[-1],\n",
        "                'Skill Match': skill_score,\n",
        "                'Experience (yrs)': round(exp_years, 1),\n",
        "                'Similarity': round(sim_score, 2),\n",
        "                'Score': round(pred * 100, 2),\n",
        "                'Alasan': '; '.join(alasan)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            results.append({\n",
        "                'Filename': getattr(cv, 'name', 'cv.pdf'),\n",
        "                'Skill Match': 0,\n",
        "                'Experience (±yrs)': 0,\n",
        "                'Similarity': 0,\n",
        "                'Score': 0,\n",
        "                'Alasan': f\"❌ Gagal diproses: {e}\"\n",
        "            })\n",
        "    df = pd.DataFrame(results).sort_values(by='Score', ascending=False)\n",
        "    return df.to_html(index=False, border=0)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "fsVRuA6Y9Q4q",
        "outputId": "957a4299-472e-4a4c-d952-15387cc30368"
      },
      "source": [
        "train_realistic_model()\n",
        "gr.Interface(\n",
        "    fn=lambda job_title, skills_csv, min_exp, cvs: match_cv_realistic(job_title, skills_csv, min_exp, cvs),\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Job Title\"),\n",
        "        gr.Textbox(label=\"Skill yang Dibutuhkan (pisahkan dengan koma)\"),\n",
        "        gr.Number(label=\"Minimal Tahun Pengalaman\"),\n",
        "        gr.File(label=\"Upload Banyak CV (PDF)\", file_types=[\".pdf\"], file_count=\"multiple\"),\n",
        "    ],\n",
        "    outputs=gr.HTML(label=\"Hasil Ranking dengan Model\"),\n",
        "    title=\"Teknikal Tes AI CV Matcher PT. Allure - Muhammad Luthfi Juliandri\"\n",
        ").launch()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://240382c7428a7314eb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://240382c7428a7314eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}